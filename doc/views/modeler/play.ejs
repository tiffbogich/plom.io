<% include ../layout %>

<div class="page-header">
  <h1> Bayesian inference with flexible and efficient tools</h1>
</div>


<div class="row">

  <div class="span1">
  </div>
  <div class="span10">

<h1><small></small></h1>


<p  class="lead" >
By adopting a Bayesian philosophy, PLoM is able to propose a simple workflow. Start defining a context, process, link and theta. Then, simply and explore the posterior density  $p(\theta,x_{0:n}|y_{1:n})$ in order to: <br>

<ol class="lead">
	<li>compare prior and posterior densities to learn and discuss parameter values</li>
	<li>derive model choice indicators to compare theories</li>
</ol>

  <h1><small>Combine fast and exact plug-and-play algorithms</small></h1>

<p class="lead" >
Recents efforts towards plug-and-play inference methods have lead to a rich diversity of algorithms to maximise and sample from probability distributions. Some rely on clever approximations and are very quick to run, and others offer the possibility to make no approximation whatsoever.
</p>
<p class="lead" >
The goal of PLoM is to take the best out of this variety of methods, making it easier and more feasible to use the most precise and demanding algorithms, while keeping everything plug-and-play.
</p>

<p class="lead" >
A standard routine we propose is to randomly sample values (<code>lhs</code>) in the parameter space, before picking the best sampled one to more carefully look for a mode of the approximated posterior density (<code>ksimplex</code>). From this mode, the same approximated posterior density is explored (<code>kmcmc</code>) to efficicently initialise the asymptotically exact particle MCMC algorithm (<code>ksimplex</code>), in its adaptive form. This webpage is meant to help you take control of each of these tools.
</p>

<h1><small>Quick peer-review to guarantee reproducibility</small></h1>
<p class="lead" >
Upload your results on plom.io to assess that your results are reliable and informative, ask validation from your peers, and instantaneously share your work.  
</p>


 </div>
</div>

<div class="page-header">
  <h1>The atomic inference command <small>One idea, one pattern</small></h1>
</div>

<div class="row">

  <div class="span12">

    <p>
      <code class="sfr-pattern">fit &#60;command&#62; [options] | ./algorithm &#60;command&#62; [options]</code>
      <ul>
        <li>
          invoked from the command line
        </li>
        <li>
          or from the programming languages you love.
        </li>
        <li>
          designed to <strong>chain</strong> inference methods
        </li>
      </ul>
      <br>
      Quickly plot your results using the PLoM R package. Corresponding commands will be given along the webpage.      
    </p>

  </div>
</div>




<div class="page-header">
  <h1>Different levels of approximation <small>Pick your choice</small></h1>
</div>


<div class="row">

  <div class="span4">
     <h3>Poisson process with stochastic rates</h3>
     In a finite population, infection dynamics are  <strong>intrinsically stochastic</strong> and the number of individuals is  <strong>discrete </strong>. <br>
     The 'psr' formalism is a natural way to  <strong>preserve these properties</strong> while remaining computationnally tractable independently of the size of the population. 
  </div>

  <div class="span4">
     <h3>Stochastic Differential Equation</h3>
     Diffusion processes are an ubiquitous family of models used to monitor the  <strong>stochastic evolution of continuous quantities </strong> over time.  <br>
     As such, the litterature and methodology on the subject is abundant. We particularly rely on approximate filtering solutions suggested by Rudoplh Kalman in the 60's, and subsequent developements.
  </div>

  <div class="span4">
     <h3>Ordinary Differential Equation</h3>
     If <strong>all sources of noise are neglected</strong>, the evolution of epidemics over time is deterministic. <br>
     Unless you are enclined to consider that your population is infinite and that all environmental factors are explicitely included in your model, results obtained under this formalism should be taken with caution.
  </div>

</div>

<div class="row">
  <div class="span12">
       <br>These formalisms respectivelly correspond to the <code>psr</code>, <code>sde</code> and  <code>ode</code> commands. Their use will be illustrated in the following sections. If you want to specifically cancel the effect of one source of stochasticity included in your model, you can use <code>--no_dem_sto</code>,  <code>--no_white_noise</code> or  <code>--no_diff</code>.
  </div> 
</div>



<div class="page-header">
  <h1>Playing around <small>Simulation and filtering</small></h1>
</div>

<div class="row">

  <div class="span4">
    <h3>Simulation</h3>

    <p>100 realisations of the observation process of your model,
      under the <code>ode</code> formalism:</p>

    <pre class="prettyprint">
fit theta | ./simul ode -J 100 --traj
</pre>

    <p>The same, but accounting for demographic stochasticity through the <code>psr</code> formalism:</p>

    <pre class="prettyprint">
fit theta | ./simul psr -J 100 --traj
</pre>

    <p><i class="icon-eye-open"></i> Plot:
      <code>plot.X()</code> and <code>plot.hat()</code>
    </p>

  </div>

  <div class="span4">
    <h3>Particle Filter</h3>

    <p>Run a particle filter (a.k.a <strong>Sequential Monte Carlo</strong>) to reconstruct the trajectories of the system given the data, using 100 particles:</p>

    <pre class="prettyprint">
fit theta | ./smc psr -J 100 --traj</pre>


    <p><i class="icon-eye-open"></i> Plot:
      <code>plot.X()</code> and <code>plot.hat()</code>
    </p>


  </div>

  <div class="span4">
    <h3>Kalman Filter</h3>

    <p>
      No time to waste with particles? Strongly believe the world is
      Gaussian? Use an <strong>Extended Kalman Filter</strong>.<br>
      Note that the EKF will only work under the <code>sde</code> formalism. 
    </p>

<pre class="prettyprint">
fit theta | ./kalman sde --traj
</pre>

   
    <p><i class="icon-eye-open"></i> Plot:
      <code>plot.X()</code>
    </p>


  </div>

</div>

<div class="row">
  <div class="span12">
    <p>
      <br>
      Yes, <strong>all this (and what follows) works</strong>
      without requiring you to recode different implementations of your
      model. Express your idea; PLoM does the dirty work.
    </p>
  </div>
</div>




<div class="page-header">
  <h1>Maximizing time and fitness <small>Trajectory matching</small></h1>
</div>

<div class="row">

  <div class="span4">
    <h3>Simplex</br> (and least-squares)</h3>
    <p>There is no stochasticity in your world and you don't even care
    about the observation process: run a Simplex for 10000
    iterations to minimize the least-squares distance.</p>

    <pre class="prettyprint">
fit theta | ./simplex -M 10000 --least_square
</pre>

    <p>OK, observation noise might matter:</p>

    <pre class="prettyprint">
fit theta | ./simplex -M 10000
</pre>


    <p><i class="icon-eye-open"></i> Plot:
      <code>plot.best()</code>
    </p>

    
  </div>

  <div class="span4">
    <h3>Simplex-Kalman (ksimplex)</h3>

    <p>You care about the demographic or environmental noise contained in your model, but you want
    to keep it fast?</p>

    <pre class="prettyprint">
fit theta | ./ksimplex -M 10000
</pre>

    <p><i class="icon-eye-open"></i> Plot:
      <code>plot.best()</code>
    </p>


  </div>

  <div class="span4">
    <h3>Iterated filtering<br>(MIF)</h3>

    <p>Want to find the maximum likelihood estimates without SDE or Gaussian approximations, accounting for both process and observation noise? Use <em>Maximum Likelihood via
        Iterated filtering</em> (MIF):</p>

    <pre class="prettyprint">
fit theta | ./mif sto -J 1000 -M 100 -a 0.95 -b 3
</pre>

    <p>Lost with the options (<code>-a</code>, <code>-M</code>, ...)? Ask for
    help: <code>./mif --help</code>. This works with every PLoM program.</p>


    <p><i class="icon-eye-open"></i> Plot:
      <code>plot.best()</code>
    </p>


  </div>

</div>

<div class="row">
<div class="span12">
  <br>    
  <p>
      To check the results of your trajectory matching, tell PLoM to use the
      previous results as initial conditions of your new algorithm using
      the <code>-B</code> option of <code>fit</code>.
      Yes, you can <strong>chain</strong> PLoM methods without
      having to edit any scripts or configuration files. Learn more about PLoM
      pipes with <code>fit --help</code>.<br>
      <strong>By default, these algorithms maximize the log-likelihood.</strong> To prepare for a posterior density 
      exploration, account for the prior with <code>--prior</code>.
  </p>
</div>
</div>





<div class="page-header">
  <h1>Explore <small>Randomly walk across the posterior density</small></h1>
</div>

<div class="row">
 
 <div class="span12">
    <p>
    Current algorithms implemented in PLoM use a random walk to explore the target density.
    This exploration relies on an underlying covariance that should capture the shape of the
    target density. This is something you are not very sure about beforehand, as it
    is what you are trying to figure out! Don't worry, the algorithm will correct itself and 
    learn progressively from what it has seen. 
    <p>
  </div>

</div>
<div class="row">

 <div class="span4">
    <h3>Kalman MCMC</h3>


    </p> 
        You have nothing against the Gaussian and SDE approximations, or want to avoid spending too much time in this learning phase, let the <code>kmcmc</code> do its part of the job!

    </p>
    <pre class="prettyprint">
fit theta | ./kmcmc sde --full -M 10000
</pre>

    <p><i class="icon-eye-open"></i> Plot:
      <code>plot.best()</code>, <code>plot.posteriors()</code> and <code>plot.corr()</code>
    </p>

  </div>

  <div class="span4">
    <h3>pMCMC</h3>

    <p>Want no Gaussian or SDE approximation? Rely on particles with the pMCMC algorithm:</p>

    <pre class="prettyprint">
fit theta | ./pmcmc psr -J 1000 -M 10000 --full
</pre>


    <p><i class="icon-eye-open"></i> Plot:
      <code>plot.best()</code>, <code>plot.posteriors()</code> and <code>plot.corr()</code>
    </p>


  </div>

  <div class="span4">
    <h3>Combine</h3>    
    <p>Ok, let's have fun:<br>
    Start with a simplex:
    </p>
    <pre class="prettyprint">fit theta | ./simplex -M 1000</pre>
    <p>Refine it with a ksimplex:</p>
    <pre class="prettyprint">fit theta -B | ./ksimplex -M 1000</pre>
    <p>Make a quick Kalman-based exploration:</p>
    <pre class="prettyprint">fit theta -B | ./kmcmc -M 2000 --full</pre>
    <p>Terminate with a pMCMC, learning the covariance from the previous run:
    <pre class="prettyprint">fit theta -B -C | ./pmcmc psr -J 1000 -M 100000 --full</pre>
    <p><i class="icon-eye-open"></i> Plot:
      <code>plot.best()</code>
    </p>

  </div>

</div>

<div class="row">
  <div class="span12">
    <p>
      Your laptop fans are spinning? Yes, by default PLoM uses all
      the available cores of your machine and runs parallel versions of the
      particle methods. <strong>C code</strong> + <strong>parallel
      computing</strong> = <strong><i class="icon-fire"></i> fast!</strong>
    </p>
  </div>
</div>



<div class="page-header">
  <h1>Escaping local maxima <small>Advanced design on the cloud</small></h1>
</div>

<div class="row">

  <div class="span6">
    <h3>LHS simplex</h3>

    <p>
      Sometimes a brute force method is all you need to explore a
      complex likelihood space. Start from 100 different initial
      conditions sampled from a <strong>Latin Hyper Square</strong>.
    </p>


    <p>Write your design in <a href="http://www.json.org/">JSON</a> <code><i class="icon-file"></i>design.json</code></p>

    <pre class="prettyprint">
{
 "name": "lhs",
 "description": "LHS design",
 "id": "lhs",
 "H": 100,
 "seed": "any string you like",
 "cmd": [
   {"fit": "-D",
    "algorithm": "simplex -M 100"}
  ]
}
</pre>

    <p>Or <strong>template</strong> it:</p>
    <pre class="prettyprint">
fit lhs theta.json "simplex -M 100" 100 --queue PBS
</pre>


    <p>Run it on the <strong>cloud</strong>:</p>

    <pre class="prettyprint">
fit bootstrap theta.json design.json --queue PBS && ./run_designs.sh 
</pre>

    <p><i class="icon-eye-open"></i> Plot:
      <code>plot.convergence()</code> and <code>plot.prs()</code>
    </p>

  </div>

  <div class="span6">
    <h3>LHS MIF</h3>

    <p>The same, with a MIF but this time using an SGE cluster.</p>
    <p>Write your design in <a href="http://www.json.org/">JSON</a> <code><i class="icon-file"></i>lhs_mif.json</code></p>
    
    <pre class="prettyprint">
{
 "name": "lhs_mif",
 "description": "LHS mif design",
 "id": "lhs",
 "H": 100,
 "seed": "any string you like",
 "cmd": [
   {"fit": "-D",
    "algorithm": "mif psr -M 100 -J 1000"}
  ]
}
</pre>

    <p>Or template it:</p>
    <pre class="prettyprint">
fit lhs theta.json "mif psr -M 100 -J 1000" 100 --queue SGE
</pre>

    <p>Run it on the cloud:</p>

    <pre class="prettyprint">
fit bootstrap theta.json design.json --queue SGE && ./run_designs.sh
</pre>

    <p><i class="icon-eye-open"></i> Plot:
      <code>plot.convergence()</code> and <code>plot.prs()</code>
    </p>
  </div>

</div>

<div class="row">
  <div class="span11">
    <h3>Chaining methods</h3>
    
    <p>
      Wonder why <code>cmd</code> is a list? Well, here too you can
      chain methods as shown by this <code><i class="icon-file"></i>design.json</code>.
    </p>

<pre class="prettyprint">
{
 "name": "lhss",
 "description": "LHS on steroids",

 "id": "lhs",
 "H": 100,
 "correlate": {
   "y": "r0:city2__all",
   "x": "r0:city1__all",
   "range": [-1, 1],
 },
 "seed": "any string you like",
 "cmd": [
   {
    "comment": "Get the initial conditions by skipping 1000 time steps",
    "fit": "-D",
    "algorithm": "simul ode -T 1000"
   },
   {
    "comment": "Refines the estimate of these (-X) values only (-I) using a simplex (least-squares)",
    "fit": "-D -X -I",
    "algorithm": "simplex --least_square -M 20000"
   },
   {
    "comment": "Concludes with a MIF that is now happily initialized and repeat that 3 times (chaining)",
    "fit": "-B",
    "algorithm": "mif psr -J 4000 -M 100",
    "repeat": 3
   }
  ]
}
</pre>

    <p>
      Note that we improved our LHS design by constraining some
      parameters to be a function of some other (here <code>r0</code>
      in the population <code>city2_all</code> is constrained to take
      the value of <code>r0</code> of the
      population <code>city1_all</code> plus some random noise draw
      from the interval specified by <code>range</code>).
    </p>


    <p>
      Keep in mind that there is no magic involved. PLoM inference
      tools use a very simple API: The scripts called
      by <code>run_designs.sh</code> are just successions
      of <code>fit</code> invocations with all the path automatically
      resolved. Remember there is only <strong>one</strong>
      pattern: <code class="sfr-pattern">fit &#60;command&#62;
      [options] | ./algorithm &#60;command&#62; [options]</code>.
    </p>

  </div>
</div>






<div class="page-header">
  <h1>Expand your knowledge <small>A first example</small></h1>
</div>

<div class="row">
  <!--
  <div class="span6">
      <a href="/doc/modeler/hfmd" class="btn btn-primary">Model selection</a>   
  </div>
  -->
   <div class="span6">
      <a href="/doc/modeler/h1n1" class="btn btn-primary">Capture unknown variations of key parameters</a>   
  </div>

</div>




<% include ../footer %>
