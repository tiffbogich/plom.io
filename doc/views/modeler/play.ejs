<% include ../layout %>

<div class="page-header">
  <h1> Bayesian inference with flexible and efficient tools</h1>
</div>


<div class="row">

  <div class="span1">
  </div>
  <div class="span10">

<h1><small></small></h1>


<p  class="lead" >
By adopting a Bayesian philosophy, PLoM is able to propose a simple workflow. Start defining a context, process, link and theta. Then, simply and explore the posterior density  $p(\theta,x_{0:n}|y_{1:n})$ in order to: <br>

<ol class="lead">
	<li>compare prior and posterior densities to learn and discuss parameter values</li>
	<li>derive model choice indicators to compare theories</li>
</ol>

  <h1><small>Combine fast and exact plug-and-play algorithms</small></h1>

<p class="lead" >
Recents efforts for plug-and-play inference methods have lead to the definition of a rich diversity of algorithms to maximise and sample from probability distributions. Some rely on clever approximations and are very quick to run. Some others offer the possibility to make no approximation whatsoever.
</p>
<p class="lead" >
The goal of PLoM is to take the best out of this variety of methods, making it easier and more feasible to use the most precise and demanding algorithms, while keeping everything plug-and-play.
</p>

<p class="lead" >
A standard routine we propose is to randomly pick values (<code>lhs</code>) in the parameter space before picking the best sampled value to more carefully look for a mode of an approximated posterior density (<code>ksimplex</code>). From this mode, the approximated posterior density is explored (<code>kmcmc</code>) to efficicently initialise the asymptotically exact particle MCMC algorithm (<code>ksimplex</code>), in its adaptive form. This webpage is meant to help you take control of each of these tools.
</p>

<h1><small>Quick peer-review to guarantee reproducibility</small></h1>
<p class="lead" >
Upload your results on plom.io to assess that your results are reliable and informative, ask validation from your peers, and instantaneously share your work.  
</p>


 </div>
</div>

<div class="page-header">
  <h1>The atomic inference command <small>One idea, one pattern</small></h1>
</div>

<div class="row">

  <div class="span12">

    <p>
      <code class="sfr-pattern">fit &#60;command&#62; [options] | ./algorithm &#60;command&#62; [options]</code>
      <ul>
        <li>
          invoked from the command line
        </li>
        <li>
          or from the programming languages you love.
        </li>
        <li>
          designed to <strong>chain</strong> inference methods
        </li>
      </ul>      
    </p>

  </div>
</div>




<div class="page-header">
  <h1>Different levels of approximation <small>Pick your choice</small></h1>
</div>


<div class="row">

  <div class="span4">
     <h3>Poisson process with stochastic rates</h3>
     In a finite population, infection dynamics are  <strong>intrinsically stochastic</strong> and the number of individuals is  <strong>discrete </strong>. <br>
     The 'psr' formalism is a natural way to  <strong>preserve these properties</strong> while remaining computationnally tractable independently of the size of the population. 
  </div>

  <div class="span4">
     <h3>Stochastic Differential Equation</h3>
     Diffusion processes are an ubiquitous family of models used to monitor the  <strong>stochastic evolution of continuous quantities </strong> over time.  <br>
     As such, the litterature and methodology on the subject is abundant. We particularly rely on approximate filtering solutions suggested by Rudoplh Kalman in the 60's, and subsequent developement.
  </div>

  <div class="span4">
     <h3>Ordinary Differential Equation</h3>
     If <strong>all sources of noise are neglected</strong>, the evolution of epidemics over time is deterministic. <br>
     Unless you are enclined to consider that your population is infinite and that all environmental factors are explicitely included in your model, results obtained under this formalism should be taken with caution.
  </div>

</div>

<div class="row">
  <div class="span12">
       <br>These formalisms respectivelly correspond to the <code>psr</code>, <code>sde</code> and  <code>ode</code> commands. Their use will be illustrated in the following sections. If you want to specifically cancel the effect of one source of stochasticity included in your model, you can use <code>--no_dem_sto</code>,  <code>--no_env_sto</code> or  <code>--no_diff</code>.
  </div> 
</div>



<div class="page-header">
  <h1>Playing around <small>Simulation and filtering</small></h1>
</div>

<div class="row">

  <div class="span4">
    <h3>Simulation</h3>

    <p>100 realisations of the observation process of your model,
      neglecting <strong>demographic stochasticity</strong>:</p>

    <pre class="prettyprint">
fit theta | ./simul deter -J 100 --traj
</pre>

    <p>The same, but <strong>with</strong> demographic stochasticity:</p>

    <pre class="prettyprint">
fit theta | ./simul sto -J 100 --traj --no_filter
</pre>

    <p><i class="icon-eye-open"></i> Plot:
      <code>plot.X()</code> and <code>plot.hat()</code>
    </p>

  </div>

  <div class="span4">
    <h3>Particle Filter</h3>

    <p>Trying to reconstruct some hidden states: run a particle filter
      (a.k.a <strong>Sequential Monte Carlo</strong>) using 100
      particles:</p>

    <pre class="prettyprint">
fit theta | ./smc sto -J 100 --traj
</pre>


    <p><i class="icon-eye-open"></i> Plot:
      <code>plot.X()</code> and <code>plot.hat()</code>
    </p>


  </div>

  <div class="span4">
    <h3>Kalman Filter</h3>

    <p>
      No time to waste with particles? Strongly believe the world is
      gaussian?<br/> Use an <strong>Extended Kalman Filter</strong>.
    </p>

<pre class="prettyprint">
fit theta | ./kalman sto --traj
</pre>

    <p>
      <code>sto</code>? Yes, we compute a diffusion approximation of
      your stochastic process so that you can assess to the demographic
      stochasticity.
    </p>

    <p><i class="icon-eye-open"></i> Plot:
      <code>plot.X()</code>
    </p>


  </div>

</div>

<div class="row">
  <div class="span12">
    <p>
      Yes, <strong>all this (and what follows) work with</strong> <code class="sfr-pattern">deter</code>
      <strong>or</strong> <code class="sfr-pattern">sto</code> and
      without requiring you to recode different implementations of your
      model. Express your idea; PLoM does the dirty work.
    </p>
  </div>
</div>




<div class="page-header">
  <h1>Maximizing time and fitness <small>Trajectory matching</small></h1>
</div>

<div class="row">

  <div class="span4">
    <h3>Simplex (and least-squares)</h3>
    <p>There is no stochasticity in your world and you don't even care
    about the observation process: Run a Simplex for 10000
    iterations.</p>

    <pre class="prettyprint">
fit theta | ./simplex -M 10000 --least_square
</pre>

    <p>OK, observation noise might matter:</p>

    <pre class="prettyprint">
fit theta | ./simplex -M 10000
</pre>


    <p><i class="icon-eye-open"></i> Plot:
      <code>plot.best()</code>
    </p>

    
  </div>

  <div class="span4">
    <h3>Simplex-Kalman (ksimplex)</h3>

    <p>You think that demographic stochasticity matters, but you want
    to keep it fast?</p>

    <pre class="prettyprint">
fit theta | ./ksimplex sto
</pre>

    <p>You neglect demographic stochasticity?</p>

    <pre class="prettyprint">
fit theta | ./ksimplex deter
</pre>

    <p><i class="icon-eye-open"></i> Plot:
      <code>plot.best()</code>
    </p>


  </div>

  <div class="span4">
    <h3>Use the results in simulation</h3>

    <p>
      Want to check out the results? Tell PLoM to use the
      previous results as initial conditions of your new algorithm using
      the <code>-B</code> option of <code>fit</code>:
    </p>

    <ul>
      <li>
        Start with a simplex:
<pre class="prettyprint">
fit theta | ./simplex -M 1000
</pre>
      </li>
<li>
      Use the result for a SMC:
<pre class="prettyprint">
fit theta -B | ./smc sto -J 100 --traj
</pre>
</li>
      
    </ul>

    

    <p><i class="icon-eye-open"></i> Plot:
      <code>plot.X()</code> and <code>plot.hat()</code>
    </p>

  </div>

</div>

<div class="row">
<div class="span12">
  Yes, you can <strong>chain</strong> PLoM methods without
  having to edit any scripts or configuration files. Learn more about PLoM
  pipes with <code>fit --help</code>.
</div>
</div>





<div class="page-header">
  <h1>No more approximations <small>Because often noise matters</small></h1>
</div>

<div class="row">

  <div class="span4">
    <h3>MIF</h3>

    <p>Want to find the <strong>maximum likelihood estimates</strong> taking into account <strong>both</strong>
        process and observation noise? Use <em>Maximum Likelihood via
        Iterated filtering</em> (MIF):</p>

    <pre class="prettyprint">
fit theta | ./mif sto -J 1000 -M 100 -a 0.95 -b 3
</pre>

    <p>Lost with the options (<code>-a</code>, <code>-M</code>, ...)? Ask for
    help: <code>./mif --help</code>. This works with every PLoM program.</p>


    <p><i class="icon-eye-open"></i> Plot:
      <code>plot.best()</code>
    </p>


  </div>

  <div class="span4">
    <h3>pMCMC</h3>

    <p>Have some priors, want to try a Bayesian approach? Use <em>particle
        Monte Carlo Markov chain</em> (pMCMC):</p>

    <pre class="prettyprint">
fit theta | ./pmcmc sto -J 1000 -M 10000
</pre>


    <p><i class="icon-eye-open"></i> Plot:
      <code>plot.best()</code>, <code>plot.posteriors()</code> and <code>plot.corr()</code>
    </p>


  </div>

  <div class="span4">
    <h3>Combine</h3>

    <p>Ok, let's have fun:</p>

    <ul>
    <li>Start with a simplex:
<pre class="prettyprint">
fit theta | ./simplex -M 1000
</pre>
    </li>

    <li>Refine it with a ksimplex:
<pre class="prettyprint">
fit theta -B | ./ksimplex sto -M 1000
</pre>
    </li>


    <li>Refine it with a MIF:
<pre class="prettyprint">
fit theta -B | ./mif sto -J 1000 -M 100 -a 0.95 -b 3
</pre>
    </li>

    <li>Terminate with a pMCMC:
<pre class="prettyprint">
fit theta -B | ./pmcmc sto -J 1000 -M 100000
</pre>
</li>
    </ul>
    <p><i class="icon-eye-open"></i> Plot:
      <code>plot.best()</code>
    </p>

  </div>

</div>

<div class="row">
  <div class="span12">
    <p>
      Your laptop fans are spinning? Yes, by default PLoM uses all
      the available cores of your machine and runs parallel versions of the
      particle methods. <strong>C code</strong> + <strong>parallel
      computing</strong> = <strong><i class="icon-fire"></i> fast!</strong>
    </p>
  </div>
</div>



<div class="page-header">
  <h1>Don't get stuck in that local maxima <small>Advanced design on the cloud</small></h1>
</div>

<div class="row">

  <div class="span6">
    <h3>LHS simplex</h3>

    <p>
      Sometimes a brute force method is all you need to explore a
      complex likelihood space. Start from 100 different initial
      conditions sampled from a <strong>Latin Hyper Square</strong>.
    </p>


    <p>Write your design in <a href="http://www.json.org/">JSON</a> <code><i class="icon-file"></i>design.json</code></p>

    <pre class="prettyprint">
{
 "name": "lhs",
 "description": "LHS design",
 "id": "lhs",
 "H": 100,
 "seed": "any string you like",
 "cmd": [
   {"fit": "-D",
    "algorithm": "simplex -M 100"}
  ]
}
</pre>

    <p>Or <strong>template</strong> it:</p>
    <pre class="prettyprint">
fit lhs theta.json "simplex -M 100" 100 --queue PBS
</pre>


    <p>Run it on the <strong>cloud</strong>:</p>

    <pre class="prettyprint">
fit bootstrap theta.json design.json --queue PBS && ./run_designs.sh 
</pre>

    <p><i class="icon-eye-open"></i> Plot:
      <code>plot.convergence()</code> and <code>plot.prs()</code>
    </p>

  </div>

  <div class="span6">
    <h3>LHS MIF</h3>

    <p>The same, with a MIF but this time using an SGE cluster.</p>
    <p>Write your design in <a href="http://www.json.org/">JSON</a> <code><i class="icon-file"></i>lhs_mif.json</code></p>
    
    <pre class="prettyprint">
{
 "name": "lhs_mif",
 "description": "LHS mif design",
 "id": "lhs",
 "H": 100,
 "seed": "any string you like",
 "cmd": [
   {"fit": "-D",
    "algorithm": "mif sto -M 100 -J 1000"}
  ]
}
</pre>

    <p>Or template it:</p>
    <pre class="prettyprint">
fit lhs theta.json "mif --sto -M 100 -J 1000" 100 --queue SGE
</pre>

    <p>Run it on the cloud:</p>

    <pre class="prettyprint">
fit bootstrap theta.json design.json --queue SGE && ./run_designs.sh
</pre>

    <p><i class="icon-eye-open"></i> Plot:
      <code>plot.convergence()</code> and <code>plot.prs()</code>
    </p>
  </div>

</div>

<div class="row">
  <div class="span11">
    <h3>Chaining methods</h3>
    
    <p>
      Wonder why <code>cmd</code> is a list? Well, here too you can
      chain methods as shown by this <code><i class="icon-file"></i>design.json</code>.
    </p>

<pre class="prettyprint">
{
 "name": "lhss",
 "description": "LHS on steroids",

 "id": "lhs",
 "H": 100,
 "correlate": {
   "y": "r0:city2__all",
   "x": "r0:city1__all",
   "range": [-1, 1],
 },
 "seed": "any string you like",
 "cmd": [
   {
    "comment": "Get the initial conditions by skipping 1000 time steps",
    "fit": "-D",
    "algorithm": "simul deter -T 1000"
   },
   {
    "comment": "Refines the estimate of these (-X) values only (-I) using a simplex (least-squares)",
    "fit": "-D -X -I",
    "algorithm": "simplex --least_square -M 20000"
   },
   {
    "comment": "Concludes with a MIF that is now happily initialized and repeat that 3 times (chaining)",
    "fit": "-B",
    "algorithm": "mif sto -J 4000 -M 100",
    "repeat": 3
   }
  ]
}
</pre>

    <p>
      Note that we improved our LHS design by constraining some
      parameters to be a function of some other (here <code>r0</code>
      in the population <code>city2_all</code> is constrained to take
      the value of <code>r0</code> of the
      population <code>city1_all</code> plus some random noise draw
      from the interval specified by <code>range</code>).
    </p>


    <p>
      Keep in mind that there is no magic involved. PLoM inference
      tools use a very simple API: The scripts called
      by <code>run_designs.sh</code> are just successions
      of <code>fit</code> invocations with all the path automatically
      resolved. Remember there is only <strong>one</strong>
      pattern: <code class="sfr-pattern">fit &#60;command&#62;
      [options] | ./algorithm &#60;command&#62; [options]</code>.
    </p>

  </div>
</div>



<div class="page-header">
  <h1>Take a first quick walk around <small>before you run a pMCMC</small></h1>
</div>

<div class="row">

  <div class="span4">
    <h3>Hey, I have priors!</h3>

    <p>
      The pMCMC is not an optimisation algorithm, so you may want to
      help it by launching an LHS ksimplex combination first. Note
      that you are interested in the posterior density rather than in
      the likelihood alone: say it with the <code>--prior</code>
      option.
    </p>

    <p>Here would be a templated <code><i class="icon-file"></i>design.json</code> example:</p>

    <pre class="prettyprint">
fit lhs theta.json "ksimplex sto -M 10000 --prior" 100</pre>

  </div>

  <div class="span4">
    <h3>All together?</h3>

     <p>
        If you have many parameters to estimate, having the pMCMC update them one by one can be long... Try the <code>--full</code> option to allow updating the whole vector at once! 
     <p>
    </p>
        It will be specifically helpful when your parameters have intricate roles in the model, but it's also a bit more adventurous. Put all luck on your side by first getting a feel of the target's shape!
    </p>
     <pre class="prettyprint">
fit theta -B | ./pmcmc sto --full -M 10000
</pre>

  </div>
  
  
  
  <div class="span4">
    <h3>Get a first feel of the target's shape</h3>

     <p>
        The pMCMC algorithm relies on an underlying covariance that should capture the shape of the target density. Of course, this is something you are not very sure about beforehand, as this is what you are trying to figure out with the pMCMC! Don't worry, the algorithm will correct itself and learn progressively from what it has seen. 
    <p>
    </p> 
        To avoid spending too much time in this learning phase, let the <code>kmcmc</code> do its part of the job: it's about 100 times faster!

    </p>
    Start with:
        <pre class="prettyprint">
fit theta -B | ./kmcmc sto --full -M 10000
</pre>
    And carry on with the pMCMC:
        <pre class="prettyprint">
fit theta -B -C | ./pmcmc sto --cov --full -M 10000
</pre>

  </div>
</div>










<div class="page-header">
  <h1>Be confident <small>and credible</small></h1>
</div>


<div class="row">
  <div class="span4">
    <h3>Store the MLE</h3>

    <p>
      Store the maximum likelihood estimate from the LHS run that gave
      the best results (let's say number 68 as reported by <code>plot.convergence()</code>). 
    </p>


<pre class="prettyprint">
fit theta -B results/lhs/best_68.output > mle.json
</pre>


  </div>


  <div class="span4">
    <h3>Slices</h3>

    <p>Compute your slices super fast and see if it is worth
    continuing...</p>


    <p>Template a design: <code><i class="icon-file"></i>slice.json</code></p>
<pre class="prettyprint">
fit --slice mle.json "smc --sto -J 1000" 20
</pre>

    <p>Run it:</p>

<pre class="prettyprint">
./run_designs.sh
</pre>

    <p><i class="icon-eye-open"></i> Plot:
      <code>plot.slices()</code></code>
    </p>
    
  </div>


  <div class="span4">
    <h3>Profiles</h3>

    <p>It is said to be an easy way to get <strong>confidence intervals</strong>.</p>

    <p>Template a design: <code><i class="icon-file"></i>profile.json</code></p>
<pre class="prettyprint">
fit --profile mle.json "mif --sto -J 1000 -M 100" 20 --queue SGE
</pre>

    <p>Run it:</p>

<pre class="prettyprint">
./run_designs.sh
</pre>


    <p><i class="icon-eye-open"></i> Plot:
      <code>plot.profiles()</code>
    </p>
        
  </div>
  
</div>


<div class="row">
  
  <div class="span6">
    <h3>Sample the peak(s)</h3>

    <p>
      Because some good posteriors are all you truly need to get <strong>credible intervals</strong>.
    </p>

    <pre class="prettyprint">
fit theta mle.json | ./pmcmc sto -J 1000 -M 10000
</pre>


    <p><i class="icon-eye-open"></i> Plot:
      <code>plot.best()</code>, <code>plot.posteriors()</code> and <code>plot.corr()</code>
    </p>

  </div>

</div>





<div class="page-header">
  <h1>Expand your knowledge <small>Inference with style</small></h1>
</div>

<div class="row">
  <!--
  <div class="span6">
      <a href="/doc/modeler/hfmd" class="btn btn-primary">Model selection</a>   
  </div>
  -->
   <div class="span6">
      <a href="/doc/modeler/h1n1" class="btn btn-primary">Capture unknown variations of key parameters</a>   
  </div>

</div>




<% include ../footer %>
